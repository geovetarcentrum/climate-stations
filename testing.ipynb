{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development of new data processing scripts for climate stations at GVC\n",
    "\n",
    "\n",
    "This notebook is just used for testing during the development of new processing scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in .dat file from logger and extract data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roof data \n",
    "file_r= '../files/taket_2015a_10.dat'\n",
    "# bridge data \n",
    "file_b= '../files/bron_2014b_10.dat'\n",
    "\n",
    "data = pd.read_table(file_r,  sep=',', header = 1, low_memory = False)\n",
    "data_r = pd.read_table(file_r,  sep=',', header = 1, low_memory = False)\n",
    "data_b = pd.read_table(file_b,  sep=',', header = 1, low_memory = False)\n",
    "\n",
    "\n",
    "# skip first two rows \n",
    "data= data.iloc[2::,:]\n",
    "# replace nan values with empty field\n",
    "data = data.replace('NAN', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['TIMESTAMP'] = pd.to_datetime(data.TIMESTAMP)\n",
    "#data['TIMESTAMP'] = data['TIMESTAMP'].dt.tz_localize('CET').dt.tz_convert('Europe/Stockholm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      2019-06-12 10:50:00+02:00\n",
       "3      2019-06-12 11:00:00+02:00\n",
       "4      2019-06-12 11:10:00+02:00\n",
       "5      2019-06-12 11:20:00+02:00\n",
       "6      2019-06-12 11:30:00+02:00\n",
       "                  ...           \n",
       "997    2019-12-26 09:50:00+01:00\n",
       "998    2019-12-26 10:00:00+01:00\n",
       "999    2019-12-26 10:10:00+01:00\n",
       "1000   2019-12-26 10:20:00+01:00\n",
       "1001   2019-12-26 10:30:00+01:00\n",
       "Name: TIMESTAMP, Length: 1000, dtype: datetime64[ns, Europe/Stockholm]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[0:1000,:]\n",
    "import pytz\n",
    "data.TIMESTAMP.dt.tz_localize(tz=pytz.FixedOffset(60)).dt.tz_convert('Europe/Stockholm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', ..., '2160', '2161', '2162'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.RECORD.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns_bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_roof = ['Wd_min_Avg', 'Wd_avg_Avg', 'Wd_max_Avg', 'Ws_min_Avg', 'Ws_avg_Avg',\n",
    "       'Ws_max_Avg', 'Ta_Avg', 'RH_Avg', 'P_Avg','REGN_Tot','REGNDYGN',\n",
    "       'SPN1_Tota_Avg', 'SPN1_diff_Avg', 'temp_L_K_Avg', 'L_sig_Avg',\n",
    "      ]\n",
    "\n",
    "columns_bridge = ['Wd_min_Avg', 'Wd_avg_Avg', 'Wd_max_Avg',\n",
    "       'Ws_min_Avg', 'Ws_avg_Avg', 'Ws_max_Avg', 'Ta_Avg', 'RH_Avg', 'P_Avg','Rc_amount_Avg', 'Rd_dur_Avg', 'Ri_intens_Avg', 'Hc_amount_Avg',\n",
    "       'Hd_dur_Avg', 'Hd_intens_Avg','Wd_min_Std', 'Wd_avg_Std', 'Wd_max_Std', 'Ws_min_Std', 'Ws_avg_Std',\n",
    "       'Ws_max_Std', 'Ta_Std', 'RH_Std', 'P_Std', 'Rc_amount_Std',\n",
    "       'Rd_dur_Std', 'Ri_intens_Std', 'Hc_amount_Std', 'Hd_dur_Std',\n",
    "       'Hd_intens_Std']\n",
    "\n",
    "meteodata_roof = ['wd_min', 'wd_avg', 'wd_max', 'ws_min', 'ws_avg', 'ws_max', 'T', 'RH', 'P', 'Precip', 'REGNDYGN',\n",
    "       'SPN1_Tota_Avg', 'SPN1_diff_Avg', 'temp_L_K_Avg', 'L_sig_Avg']\n",
    "meteodata_bridge = ['wd_min', 'wd_avg', 'wd_max', 'ws_min', 'ws_avg', 'ws_max', 'T', 'RH', 'P', 'Rc_amount_Avg', 'Rd_dur_Avg', 'Ri_intens_Avg', 'Hc_amount_Avg',\n",
    "       'Hd_dur_Avg', 'Hd_intens_Avg','wd_max_std', 'wd_avg_std', 'wd_min_std', 'ws_min_std', 'ws_avg_std', 'ws_max_std', 'T_std', 'RH_Std', 'P_std', 'Rc_amount_std', 'Rd_dur_std', 'Ri_intens_std', 'Hc_amount_std',\n",
    "       'Hd_dur_std', 'Hd_intens_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save date as: Year, DOY, HHHMM \n",
    "data['time'] = pd.to_datetime(data.TIMESTAMP)\n",
    "data['year'] = data.time.dt.year\n",
    "data['hhmm']= data.time.dt.hour.astype(str) + data.time.dt.minute.astype(str)\n",
    "data['doy'] = data.time.dt.dayofyear\n",
    "data['code'] = data.RECORD.values\n",
    "\n",
    "data= data[data.time.dt.year == 2020]\n",
    "\n",
    "# create new data frame \n",
    "df= pd.DataFrame(dtype = 'object')\n",
    "df['year'] = data.time.dt.year\n",
    "df['hhmm']= data.time.dt.hour.astype(str) + data.time.dt.minute.astype(str)\n",
    "df['doy'] = data.time.dt.dayofyear.astype(str)\n",
    "df['code'] = data.RECORD.values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TIMESTAMP', 'RECORD', 'LUFTTEMP_Avg', 'LUFTFUKT_Avg',\n",
       "       'VINDHAST_WVc(1)', 'VINDHAST_WVc(2)', 'VINDHAST_WVc(3)', 'REGN_Tot',\n",
       "       'REGNDYGN', 'Lufttryck_Avg', 'Ltryckhel_Avg', 'Ltrydec_Avg',\n",
       "       'SPN1_Tota_Avg', 'SPN1_diff_Avg', 'temp_L_K_Avg', 'L_sig_Avg',\n",
       "       'Wd_min_Avg', 'Wd_avg_Avg', 'Wd_max_Avg', 'Ws_min_Avg', 'Ws_avg_Avg',\n",
       "       'Ws_max_Avg', 'Ta_Avg', 'RH_Avg', 'P_Avg', 'Rc_amount_Avg',\n",
       "       'Rd_dur_Avg', 'Ri_intens_Avg', 'Hc_amount_Avg', 'Hd_dur_Avg',\n",
       "       'Hd_intens_Avg', 'Ws_avg_WVc(1)', 'Ws_avg_WVc(2)', 'Ws_avg_WVc(3)',\n",
       "       'BATTERI_Min', 'BATTERI_TMn', 'time', 'year', 'hhmm', 'doy', 'code'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Meteo data Roof \n",
    "\n",
    "# relative humidity (%)\n",
    "df['RH'] = data.RH_Avg.values.astype(float)\n",
    "# pressure (hPa)\n",
    "df['P'] = data.P_Avg.values.astype(float)\n",
    "# mean air temperature (degC)\n",
    "df['Ta']  = data.Ta_Avg.values\n",
    "# mean wind speed (m/s)\n",
    "df['ws']  = data.Ws_avg_Avg.values.astype(float)\n",
    "# min wind speed (m/s)\n",
    "df['ws_max']  = data.Ws_min_Avg.values.astype(float)\n",
    "# max wind speed (m/s)\n",
    "df['ws_min']  = data.Ws_max_Avg.values.astype(float)\n",
    "# mean wind direction (deg)\n",
    "df['wd']  = data.Ws_avg_Avg.values.astype(float)\n",
    "# min wind direction (deg)\n",
    "df['wd_max']  = data.Ws_min_Avg.values.astype(float)\n",
    "# max wind direction (deg)\n",
    "df['wd_min']  = data.Ws_max_Avg.values.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Meteo data Bridge \n",
    "\n",
    "# relative humidity (%)\n",
    "df['RH'] = data.RH_Avg.values.astype(float)\n",
    "# pressure (hPa)\n",
    "df['P'] = data.P_Avg.values.astype(float)\n",
    "# mean air temperature (degC)\n",
    "df['Ta']  = data.Ta_Avg.values\n",
    "# mean wind speed (m/s)\n",
    "df['ws']  = data.Ws_avg_Avg.values.astype(float)\n",
    "# min wind speed (m/s)\n",
    "df['ws_max']  = data.Ws_min_Avg.values.astype(float)\n",
    "# max wind speed (m/s)\n",
    "df['ws_min']  = data.Ws_max_Avg.values.astype(float)\n",
    "# mean wind direction (deg)\n",
    "df['wd']  = data.Ws_avg_Avg.values.astype(float)\n",
    "# min wind direction (deg)\n",
    "df['wd_max']  = data.Ws_min_Avg.values.astype(float)\n",
    "# max wind direction (deg)\n",
    "df['wd_min']  = data.Ws_max_Avg.values.astype(float)\n",
    "\n",
    "## standard deviations\n",
    "\n",
    "# relative humidity (%)\n",
    "df['RH_std'] = data.RH_Std.values.astype(float)\n",
    "# pressure (hPa)\n",
    "df['P_std'] = data.P_Std.values.astype(float)\n",
    "# mean air temperature (degC)\n",
    "df['Ta_std']  = data.Ta_Std.values\n",
    "# mean wind speed (m/s)\n",
    "df['ws_std']  = data.Ws_avg_Std.values.astype(float)\n",
    "# min wind speed (m/s)\n",
    "df['ws_max_std']  = data.Ws_min_Std.values.astype(float)\n",
    "# max wind speed (m/s)\n",
    "df['ws_min_std']  = data.Ws_max_Std.values.astype(float)\n",
    "# mean wind direction (deg)\n",
    "df['wd_std']  = data.Ws_avg_Std.values.astype(float)\n",
    "# min wind direction (deg)\n",
    "df['wd_max_std']  = data.Ws_min_Std.values.astype(float)\n",
    "# max wind direction (deg)\n",
    "df['wd_min_std']  = data.Ws_max_Std.values.astype(float)\n",
    "\n",
    "\n",
    "## quality flags for meteorological variables \n",
    "\n",
    "# relative humidity (%)\n",
    "df['RH_QC'] = 0\n",
    "# pressure (hPa)\n",
    "df['P_QC'] = 0\n",
    "# mean air temperature (degC)\n",
    "df['Ta_QC']  = 0\n",
    "# mean wind speed (m/s)\n",
    "df['ws_QC']  = 0\n",
    "# min wind speed (m/s)\n",
    "df['ws_max_QC']  = 0\n",
    "# max wind speed (m/s)\n",
    "df['ws_min_QC']  = 0\n",
    "# mean wind direction (deg)\n",
    "df['wd_QC']  = 0\n",
    "# min wind direction (deg)\n",
    "df['wd_max_QC']  = 0\n",
    "# max wind direction (deg)\n",
    "df['wd_min_QC']  = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quality control flags \n",
    "\n",
    "- 0: passed all quality tests \n",
    "- 1: not in plausible range\n",
    "- 2: mutual exclusion/ inconsistency \n",
    "- 3: error in time evolution (not over minimum standard deviation of last hour) \n",
    "- 4: error in time consistency (abrupt jumps in values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All quality tests are based on recommendations from the WMO (ref). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test with a small sample of dataframe \n",
    "subsample = df.head()\n",
    "df= subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['QC_flag'] = 1\n",
    "\n",
    "for i in df.index.values:\n",
    "    \n",
    "    rh = df[df.index == i].RH.values[0]\n",
    "    pr = df[df.index == i].P.values[0]\n",
    "    ta = df[df.index == i].Ta.values[0]\n",
    "    wd = df[df.index == i].wd.values[0]\n",
    "    ws = df[df.index == i].ws.values[0]\n",
    "\n",
    "    if i > 2 :\n",
    "        p= i - 1 \n",
    "        rh_p = df[df.index == p ].RH.values[0]\n",
    "        pr_p = df[df.index == p ].P.values[0]\n",
    "        ta_p = df[df.index == p].Ta.values[0]\n",
    "        wd_p = df[df.index == p].wd.values[0]\n",
    "        ws_p = df[df.index == p].ws.values[0]\n",
    "        \n",
    "\n",
    "    if i < np.shape(df.index.values)[0]:\n",
    "        n= i+1\n",
    "        rh_n = df[df.index == n].RH.values[0]\n",
    "        pr_n = df[df.index == n].P.values[0]\n",
    "        ta_n = df[df.index == n].Ta.values[0]\n",
    "        wd_n = df[df.index == n].wd.values[0]\n",
    "        ws_n = df[df.index == n].ws.values[0]\n",
    "\n",
    "    # plausible ranges\n",
    "    if rh < 0 or rh > 100:\n",
    "         df.loc[i, 'QC_flag'] = 4\n",
    "    if  pr < 500 or pr > 1100:\n",
    "        df.loc[i, 'QC_flag'] = 4\n",
    "    if wd < 0 or wd > 360:\n",
    "        df.loc[i, 'QC_flag'] = 4      \n",
    "    if ws < 0 or ws > 75:\n",
    "        df.loc[i, 'QC_flag'] = 4\n",
    "        \n",
    "    # internal inconsistencies \n",
    "    if wd == 0 and ws > 0:\n",
    "        df.loc[i, 'QC_flag'] = 4\n",
    "    if ws == 0 and wd > 0:\n",
    "        df.loc[i, 'QC_flag'] = 4\n",
    "        \n",
    "    # time consistency (check for jumps in data)\n",
    "    ts= np.absolute(wd - wd_p) + np.absolute(wd - wd_n) \n",
    "    std= 4 * df[df.index == i].wd_std.values[0]\n",
    "    if  ts > std :\n",
    "        df.loc[i, 'QC_flag'] = 3\n",
    "\n",
    "    ts= np.absolute(ws - ws_p) + np.absolute(ws - ws_n) \n",
    "    std= 4 * df[df.index == i].wd_std.values[0]\n",
    "    if  ts > std :\n",
    "        df.loc[i, 'QC_flag'] = 3\n",
    "\n",
    "    ts= np.absolute(pr - pr_p) + np.absolute(pr - pr_n) \n",
    "    std= 4 * df[df.index == i].wd_std.values[0]\n",
    "    if  ts > std :\n",
    "        df.loc[i, 'QC_flag'] = 3\n",
    "\n",
    "    ts= np.absolute(rh - rh_p) + np.absolute(rh - rh_n) \n",
    "    std= 4 * df[df.index == i].wd_std.values[0]\n",
    "    if  ts > std :\n",
    "        df.loc[i, 'QC_flag'] = 3\n",
    "  \n",
    "    # minimum standard deviation of last 60 minutes \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3\n",
       "3    1\n",
       "4    3\n",
       "5    1\n",
       "6    1\n",
       "Name: QC_flag, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.QC_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Saving format of monthly files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check whether one month has passed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create CSV file according to standard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonizing historical data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- same columns in all monthly files \n",
    "- flags for quality control \n",
    "- metadata  (location, explanation of variable names, units) in a header at the top  of the file with # to indicate these are comments. A blank line with  leading # to separate the metadata from the column headers\n",
    "- make  the actual column headers legal variable names eg T_max, not “Maximum  temperature (degC)”.\n",
    "- Put the explanation in the header.\n",
    "-   column header line also has a leading \n",
    "- use a ; separator, dont use fixed-width or space separated. \n",
    "-  indicate  missing values by not having a value! eg ;; Now, test that R and pandas  are ok with this, but it will reduce the file-size dramatically  compared with -999 or “NaN”. Currently the files in BridgeData total about 600MB, which is absurd. \n",
    "- similarly, don’t use more decimal places than the precision of the actual measurements.\n",
    "- UTF-8 with linefeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## write header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headerstr= 'Roof station GVC \\nLon: 11.966434 \\nLat: 57.688374 \\nTa: Air temperature [degC], RH: Relative Humidity [%], P: Air pressure [hpa], Ws: 10min mean wind speed [m/s], Wind direction [deg], \\nQC: quality flags (0 = passed all controls, 1 = not in plausible range, 2 = inconsistency, 3 = same value, 4 = big jump)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roof station GVC \n",
      "Lon: 11.966434 \n",
      "Lat: 57.688374 \n",
      "Ta: Air temperature [degC], RH: Relative Humidity [%], P: Air pressure [hpa], Ws: 10min mean wind speed [m/s], Wind direction [deg], \n",
      "QC: quality flags (0 = passed all controls, 1 = not in plausible range, 2 = inconsistency, 3 = same value, 4 = big jump)\n"
     ]
    }
   ],
   "source": [
    "print(headerstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Notes Julia - Identify usable columns in historical data files: ** \n",
    "\n",
    "- Ta (Ta.1?)\n",
    "- RH (RH.1?)\n",
    "- P\n",
    "- Wd_avg, Wd_min, Wd_max , Wd_std\n",
    "- Ws_avg, Ws_min, Ws_max\n",
    "- radiation columns?? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
